{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using C:\\Users\\ls\\AppData\\Local\\torch_extensions\\torch_extensions\\Cache\\py39_cu124 as PyTorch extensions root...\n",
      "Creating extension directory C:\\Users\\ls\\AppData\\Local\\torch_extensions\\torch_extensions\\Cache\\py39_cu124\\differentiable_rapid_raditor...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file C:\\Users\\ls\\AppData\\Local\\torch_extensions\\torch_extensions\\Cache\\py39_cu124\\differentiable_rapid_raditor\\build.ninja...\n",
      "c:\\Users\\ls\\anaconda3\\envs\\stimulate\\lib\\site-packages\\torch\\utils\\cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module differentiable_rapid_raditor...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module differentiable_rapid_raditor...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "differentiable_rapid_raditor = load(\n",
    "    name=\"differentiable_rapid_raditor\",\n",
    "    sources=[\"utils/differentiable_rapid_raditor_kernel.cpp\", \"utils/differentiable_rapid_raditor_kernel_v3_fine.cu\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom Autograd Function\n",
    "class SimulateFunction(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times):\n",
    "        # Call the C++ forward function\n",
    "        simulate_record = differentiable_rapid_raditor.simulate(\n",
    "            sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times)\n",
    "        \n",
    "        # Save inputs for backward\n",
    "        ctx.save_for_backward(sensor_location, source_location, source_p0, source_dx)\n",
    "        ctx.dt = dt\n",
    "        ctx.num_sensors = num_sensors\n",
    "        ctx.num_sources = num_sources\n",
    "        ctx.num_times = num_times\n",
    "        \n",
    "        return simulate_record  # simulate_record：torch.Size([num_sensors * num_times])\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dsimulate_record):\n",
    "        # dL_dsimulate_record：torch.Size([num_sensors * num_times])\n",
    "        sensor_location, source_location, source_p0, source_dx = ctx.saved_tensors\n",
    "        dt = ctx.dt\n",
    "        num_sensors = ctx.num_sensors\n",
    "        num_sources = ctx.num_sources\n",
    "        num_times = ctx.num_times\n",
    "\n",
    "\n",
    "        # Call the C++ backward function\n",
    "        grad_source_location, grad_source_p0, grad_source_dx = differentiable_rapid_raditor.simulate_backward(\n",
    "            sensor_location, source_location, source_p0, source_dx, dL_dsimulate_record.contiguous(), dt, num_sensors, num_sources, num_times\n",
    "        )\n",
    "        return None, grad_source_location, grad_source_p0, grad_source_dx, None, None, None, None\n",
    "\n",
    "# Utility function to use the custom autograd function\n",
    "def simulate(sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times):\n",
    "    return SimulateFunction.apply(sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ls\\Desktop\\SlingBAG\\utils\\sliding_ball_model_fine.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._xyz = Parameter(torch.tensor(xyz, dtype=torch.float32) if xyz is not None else torch.empty(0))\n",
      "c:\\Users\\ls\\Desktop\\SlingBAG\\utils\\sliding_ball_model_fine.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._pressure_0 = Parameter(torch.tensor(pressure_0, dtype=torch.float32) if pressure_0 is not None else torch.empty(0))\n",
      "c:\\Users\\ls\\Desktop\\SlingBAG\\utils\\sliding_ball_model_fine.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._radius = Parameter(torch.tensor(radius, dtype=torch.float32) if radius is not None else torch.empty(0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80413 balls loaded from point cloud file.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Function\n",
    "from utils.loss_utils import l2_loss\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from utils.sliding_ball_model_fine import SlidingBallModel  \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    balls = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        start = False\n",
    "        for line in lines:\n",
    "            if start:\n",
    "                data = line.split()\n",
    "                if len(data) == 5:\n",
    "                    xyz = torch.tensor([float(data[0]), float(data[1]), float(data[2])], requires_grad=True, dtype=torch.float32, device=device)\n",
    "                    pressure_0 = torch.tensor(float(data[3]), requires_grad=True, dtype=torch.float32, device=device)\n",
    "                    radius = torch.tensor(float(data[4]), requires_grad=True, dtype=torch.float32, device=device)\n",
    "                    ball = SlidingBallModel(xyz, pressure_0, radius)\n",
    "                    balls.append(ball)\n",
    "            if 'end_header' in line:\n",
    "                start = True\n",
    "    return balls\n",
    "\n",
    "file_path = 'point_cloud_coarse/ball_300_after.ply'\n",
    "balls = load_point_cloud(file_path)\n",
    "print(f\"{len(balls)} balls loaded from point cloud file.\")\n",
    "\n",
    "# 随机初始化球分布\n",
    "def generate_random_balls(num_balls, boundaries, res):\n",
    "    balls = []\n",
    "    x_min, x_max, y_min, y_max, z_min, z_max = boundaries\n",
    "    for _ in range(num_balls):\n",
    "        xyz = torch.tensor([random.uniform(x_min, x_max), random.uniform(y_min, y_max), random.uniform(z_min, z_max)], requires_grad=False, dtype=torch.float32, device=device)\n",
    "        pressure_0 = torch.tensor(random.uniform(20, 100), requires_grad=True, dtype=torch.float32, device=device)\n",
    "        radius = torch.tensor(random.uniform(1*res, 6*res), requires_grad=True, dtype=torch.float32, device=device)\n",
    "        ball = SlidingBallModel(xyz, pressure_0, radius)\n",
    "        balls.append(ball)\n",
    "    return balls\n",
    "\n",
    "# 迭代函数\n",
    "def run_iterations(balls, pressure_threshold, radius_max_threshold, radius_min_threshold, boundaries):\n",
    "    new_balls = []\n",
    "    for ball in balls:\n",
    "        new_ball = ball.adaptive_density_optimization(pressure_threshold, radius_max_threshold, radius_min_threshold, boundaries)\n",
    "        if new_ball is not None:\n",
    "            new_balls.append(new_ball)\n",
    "    balls = [ball for ball in balls if not ball._is_destroyed] + new_balls\n",
    "    return balls\n",
    "\n",
    "# 保存点云数据函数\n",
    "def save_point_cloud(balls, filename):\n",
    "    points = []\n",
    "    for ball in balls:\n",
    "        if not ball._is_destroyed:\n",
    "            xyz = ball._xyz.detach().cpu().numpy()  # 转为 numpy 数组\n",
    "            pressure_0 = ball._pressure_0.item()  # 提取标量值\n",
    "            radius = ball._radius.item()  # 提取标量值\n",
    "            points.append([xyz[0], xyz[1], xyz[2], pressure_0, radius])\n",
    "\n",
    "    with open(filename, \"w\") as ply_file:\n",
    "        # 写 PLY 文件头\n",
    "        ply_file.write(\"ply\\n\")\n",
    "        ply_file.write(\"format ascii 1.0\\n\")\n",
    "        ply_file.write(f\"element vertex {len(points)}\\n\")\n",
    "        ply_file.write(\"property float x\\n\")\n",
    "        ply_file.write(\"property float y\\n\")\n",
    "        ply_file.write(\"property float z\\n\")\n",
    "        ply_file.write(\"property float pressure_0\\n\")\n",
    "        ply_file.write(\"property float radius\\n\")\n",
    "        ply_file.write(\"end_header\\n\")\n",
    "        \n",
    "        # 写入每个点的信息\n",
    "        for point in points:\n",
    "            ply_file.write(f\"{point[0]} {point[1]} {point[2]} {point[3]} {point[4]}\\n\")\n",
    "\n",
    "# 参数设置\n",
    "num_times = 4096\n",
    "Nt = num_times\n",
    "res = 0.20e-3\n",
    "Vs = 1500.0\n",
    "dt = 25e-9  # [s]\n",
    "folder_name = \"point_cloud_fine\"\n",
    "boundaries = (0, 400 * res, 0, 520 * res, 0, 200 * res)\n",
    "source_num = len(balls)\n",
    "pressure_threshold = 15.0\n",
    "radius_max_threshold = 3 * res\n",
    "radius_min_threshold = 0.5 * res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 4096)\n",
      "(196, 3)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# load sensor information\n",
    "sensor_data_matrix = np.loadtxt('data/planar_196_sensor_data.txt', delimiter='\\t')\n",
    "real_signal = sensor_data_matrix\n",
    "sensor_location = np.loadtxt('data/planar_196_sensor_location.txt', delimiter='\\t')\n",
    "sensor_location = sensor_location*1e-3\n",
    "sensor_num = sensor_location.shape[0]\n",
    "print(real_signal.shape)\n",
    "print(sensor_location.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代 1，损失: 288.9027404785156，时间: 269.38558626174927\n"
     ]
    }
   ],
   "source": [
    "# 将数据转为PyTorch张量，并移动到GPU\n",
    "sensor_location = torch.tensor(sensor_location,dtype=torch.float, device=device)\n",
    "real_signal = torch.tensor(real_signal,dtype=torch.float)\n",
    "real_signal_flat = real_signal.flatten()\n",
    "real_signal_flat = real_signal_flat.to(device)\n",
    "\n",
    "# 将所有参数按照不同学习率进行分组\n",
    "def get_optim_params(balls):\n",
    "    params_xyz = [ball._xyz for ball in balls]\n",
    "    params_pressure = [ball._pressure_0 for ball in balls]\n",
    "    params_radius = [ball._radius for ball in balls]\n",
    "    return [\n",
    "        {'params': params_xyz, 'lr': 0.000004},\n",
    "        {'params': params_pressure, 'lr': 0.004},\n",
    "        {'params': params_radius, 'lr': 0.000004},\n",
    "    ]\n",
    "\n",
    "optimizer = optim.Adam(get_optim_params(balls), betas=(0.9, 0.999))\n",
    "\n",
    "# 设置学习率调度器\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "# 开始迭代训练\n",
    "for iter in range(num_iterations):\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 使用当前球的参数传递给simulate函数\n",
    "    source_location = torch.stack([ball._xyz for ball in balls]).flatten()\n",
    "    source_p0 = torch.stack([ball._pressure_0 for ball in balls]).flatten()\n",
    "    radius_0 = torch.stack([ball._radius for ball in balls]).flatten()\n",
    "    \n",
    "    simulate_record = simulate(sensor_location, source_location, source_p0, radius_0, dt, sensor_num, source_num, num_times)  \n",
    "    loss = l2_loss(simulate_record, real_signal_flat)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    end_time = time.time()  # 记录结束时间\n",
    "    iteration_time = end_time - start_time  # 计算时间差\n",
    "    print(f\"迭代 {iter + 1}，损失: {loss.item()}，时间: {iteration_time}\")\n",
    "    # 更新每个球的参数，以确保它们在相应的实例中\n",
    "    for ball in balls:\n",
    "        ball._xyz.data = ball._xyz.data.requires_grad_(True)\n",
    "        ball._pressure_0.data = ball._pressure_0.data.requires_grad_(True)\n",
    "        ball._radius.data = ball._radius.data.requires_grad_(True)\n",
    "\n",
    "    # 每10次迭代前保存点云数据到文件\n",
    "    if (iter + 1) % 10 == 0:\n",
    "        filename = f\"ball_{iter + 1}_before.ply\"\n",
    "        full_path = os.path.join(folder_name, filename)\n",
    "        save_point_cloud(balls, full_path)\n",
    "        print(f\"Point cloud saved to {filename}\")\n",
    "\n",
    "    # 每20次迭代进行自适应密度优化\n",
    "    if (iter + 1) % 20 == 0:\n",
    "        with torch.no_grad():\n",
    "            # 更新每个球的梯度状态，为下一次分裂做准备\n",
    "            for ball in balls:\n",
    "                ball._xyz.grad = ball._xyz.grad / torch.norm(ball._xyz.grad, p=2) if ball._xyz.grad is not None else None\n",
    "\n",
    "            balls = run_iterations(balls, pressure_threshold, radius_max_threshold, radius_min_threshold, boundaries)\n",
    "            source_num = len(balls)  # 更新 source_num 为当前球的数量\n",
    "\n",
    "        # 打印当前球的数量\n",
    "        print(f\"After {iter + 1} iterations, number of balls: {source_num}\")\n",
    "\n",
    "        # 更新优化器中的参数\n",
    "        optimizer = optim.Adam(get_optim_params(balls), betas=(0.9, 0.999))\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "    # 每10次迭代后保存点云数据到文件\n",
    "    if (iter + 1) % 10 == 0:\n",
    "        filename = f\"ball_{iter + 1}_after.ply\"\n",
    "        full_path = os.path.join(folder_name, filename)\n",
    "        save_point_cloud(balls, full_path)\n",
    "        print(f\"Point cloud saved to {filename}\")\n",
    "\n",
    "    if (iter + 1) % 100 == 40:\n",
    "        with torch.no_grad():\n",
    "            new_balls = []\n",
    "            for ball in balls:\n",
    "                if ball._xyz.grad is not None:\n",
    "                    gradient_direction = ball._xyz.grad\n",
    "                    new_ball = ball.clone_along_gradient(gradient_direction, boundaries,res)\n",
    "                    if new_ball is not None:\n",
    "                        new_balls.append(new_ball)\n",
    "            balls.extend(new_balls)\n",
    "            source_num = len(balls)  # 更新 source_num 为当前球的数量\n",
    "\n",
    "        # 打印当前球的数量\n",
    "        print(f\"After {iter + 1} iterations with cloning, number of balls: {source_num}\")\n",
    "\n",
    "        # 更新优化器中的参数\n",
    "        optimizer = optim.Adam(get_optim_params(balls), betas=(0.9, 0.999))\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "        # 保存点云\n",
    "        filename = f\"ball_{iter + 1}_after_duplication.ply\"\n",
    "        full_path = os.path.join(folder_name, filename)\n",
    "        save_point_cloud(balls, full_path)\n",
    "        print(f\"Point cloud saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stimulate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
